[{
  "caption": "Table 1: Results on val. set of Smt-Smt-V2 showing the importance of salient regions discovery. We compare our predicted (unsupervised) regions to fixed grid regions or boxes given by an object detector using the same GNN model. The mean L2 distance between the regions and gt. objects proves that DyReG-GNN has regions correlated with objects, while also having superior accuracy and efficiency.",
  "captionBoundary": {
    "x1": 107.69100189208984,
    "x2": 343.3836364746094,
    "y1": 73.6335220336914,
    "y2": 145.09100341796875
  },
  "figType": "Table",
  "imageText": ["4", "Experimental", "Analysis195", "+", "GNN+Fixed", "Grid", "+1.4G", "0.170", "64.1", "+", "GNN+Detector", "Obj", "detector", "+41.1G", "0.125", "64.0", "+", "DyReg-GNN", "Unsupervised", "+1.6G", "0.129", "64.8", "TSM-R50", "-", "65.8G", "-", "63.4", "Model", "Regions", "FLOPS", "Dist", "Acc", "discovery", "↓", "↓", "(%)↑"],
  "name": "1",
  "page": 5,
  "regionBoundary": {
    "x1": 87.84,
    "x2": 343.2,
    "y1": 156.96,
    "y2": 251.51999999999998
  },
  "renderDpi": 150,
  "renderURL": "NeurIPS_2021_pic_2E4AT-qj3Dg-Table1-1.png"
}, {
  "caption": "Table 2: Consistent improvements over different backbones on the validation set of Smt-Smt-V1 using central crop evaluation.",
  "captionBoundary": {
    "x1": 349.2510070800781,
    "x2": 505.6556091308594,
    "y1": 82.46353912353516,
    "y2": 121.1929931640625
  },
  "figType": "Table",
  "imageText": ["TSM-R50", "47.2", "TSM-R50", "+", "DyReg-GNN", "48.8", "(↑", "1.6)", "I3D-R50", "44.0", "I3D-R50", "+", "DyReg-GNN", "45.4", "(↑", "1.4)", "TSM-R18", "33.7", "TSM-R18", "+", "DyReg-GNN", "35.6", "(↑", "1.9)", "Model", "Acc", "(%)"],
  "name": "2",
  "page": 5,
  "regionBoundary": {
    "x1": 348.96,
    "x2": 510.24,
    "y1": 132.96,
    "y2": 220.79999999999998
  },
  "renderDpi": 150,
  "renderURL": "NeurIPS_2021_pic_2E4AT-qj3Dg-Table2-1.png"
}, {
  "caption": "Figure 1: (Left) DyReg-GNN extracts localized node useful for relational processing of videos. For each node i, from the features Xt, we predict params oi denoting the location and size of a region. They define a kernel Ki, used to extract the localized features vi from the corresponding region of Xt. We process the nodes with a spatio-temporal GNN and project each node v̂i into its initial location. (Right) B) Node Region Generation: Functions f and {gi} generate the regions params oi; f extracts a latent representation shared between nodes, while each gi has different params for each node i. C) Node Features Extraction: Each oi creates a kernel that is used in a differentiable pooling w.r.t. oi. This allows us to optimize the generation of these regions’ params from the final classification loss, resulting in an unsupervised discovery of salient regions.",
  "captionBoundary": {
    "x1": 107.69100189208984,
    "x2": 505.7392883300781,
    "y1": 203.13455200195312,
    "y2": 296.40899658203125
  },
  "figType": "Figure",
  "imageText": [],
  "name": "1",
  "page": 2,
  "regionBoundary": {
    "x1": 108.0,
    "x2": 504.0,
    "y1": 70.56,
    "y2": 195.35999999999999
  },
  "renderDpi": 150,
  "renderURL": "NeurIPS_2021_pic_2E4AT-qj3Dg-Figure1-1.png"
}, {
  "caption": "Figure 2: Nodes’ regions on MultiSyncMNIST for 3 frames. a) Static Model, ignoring the input, learns a regular grid; b) Constant-Time predicts the same regions for all time steps, covering the movement in the video; c) The attention map of a single node of Semantic that can’t distinguish between different instances of the same digit; d) DyReg-GNN generally follows the digits locations at each time steps while also adapting the regions’ size.",
  "captionBoundary": {
    "x1": 107.69100189208984,
    "x2": 326.630615234375,
    "y1": 166.60855102539062,
    "y2": 248.9749755859375
  },
  "figType": "Figure",
  "imageText": [],
  "name": "2",
  "page": 7,
  "regionBoundary": {
    "x1": 109.92,
    "x2": 324.0,
    "y1": 70.56,
    "y2": 159.35999999999999
  },
  "renderDpi": 150,
  "renderURL": "NeurIPS_2021_pic_2E4AT-qj3Dg-Figure2-1.png"
}, {
  "caption": "Figure 3: Nodes’ regions on Smt-Smt-V2. We show (1st row) the center of all the N regions as predicted by DyReg-GNN (each color for a node). Each node region (last 2 rows) corresponds to a zone from the latent conv features pooled by a node.",
  "captionBoundary": {
    "x1": 337.2120056152344,
    "x2": 505.7389831542969,
    "y1": 183.51553344726562,
    "y2": 244.06402587890625
  },
  "figType": "Figure",
  "imageText": [],
  "name": "3",
  "page": 7,
  "regionBoundary": {
    "x1": 336.96,
    "x2": 504.0,
    "y1": 75.84,
    "y2": 175.2
  },
  "renderDpi": 150,
  "renderURL": "NeurIPS_2021_pic_2E4AT-qj3Dg-Figure3-1.png"
}]