{
  "ID": "-IHPcl1ZhF5",
  "Title": "RISE: Robust Individualized Decision Learning with Sensitive Variables",
  "URL": "https://openreview.net/forum?id=-IHPcl1ZhF5",
  "paper_draft_url": "/references/pdf?id=HSc7FtUS5l",
  "Conferece": "NeurIPS_2022",
  "input": {
    "source": "CRF",
    "title": "RISE: Robust Individualized Decision Learning with Sensitive Variables",
    "authors": [],
    "emails": [],
    "sections": [
      {
        "heading": null,
        "text": "This paper introduces RISE, a robust individualized decision learning framework1 with sensitive variables, where sensitive variables are collectible data and important2 to the intervention decision, but their inclusion in decision making is prohibited3 due to reasons such as delayed availability or fairness concerns. The convention is4 to ignore these sensitive variables in learning decision rules, leading to significant5 uncertainty and bias. To address this, we propose a decision learning framework6 to incorporate sensitive variables during offline training but do not include them7 in the input of the learned decision rule during deployment. Specifically, from8 a causal perspective, the proposed framework intends to improve the worst-case9 outcomes of individuals caused by sensitive variables that are unavailable at the10 time of decision. Unlike most existing literature that uses mean-optimal objectives,11 the proposed learning framework robustifies sensitive variables via finding a newly12 defined quantile- or infimum-optimal decision rule for improving the worst-off13 group among all sensitive variable realizations. The reliable performance of the14 proposed method is demonstrated through synthetic experiments and three real-data15 applications.16\n1 Introduction17\nRecently, there has been a widespread interest in developing methodology for individualized decision18 rules (IDRs) based on observational data. When deriving IDRs, some collectible data are important19 to the intervention decision, while their inclusion in decision making is prohibited due to reasons20 such as delayed availability or fairness concerns. For example, sensitive characteristics of subjects21 regarding their income, sex, race and ethnicity may not be appropriate to be used directly for22 decision making due to fairness concerns. In the medical field especially for patients in severe23 life-threatening conditions such as sepsis, timely bedside intervention decisions have to be made24 before lab measurements are ordered, assayed and returned to the attending physicians. However, due25 to the delayed availability of lab results, most of the decisions are made with great uncertainty and26 bias due to partial information at hand. We define sensitive variables as variables whose inclusion into27 decision rules is prohibited. The formal definition of sensitive variables will be given in Section 3.28\nIn this work, we propose RISE (Robust Individualized decision learning with SEnsitive variables), a29 robust IDR framework to improve the outcome of individuals when there are informative yet sensitive30 variables that are either not available or prohibited from using during IDR deployment. The main31 question of interest is whether the learned IDR could yield similar outcomes across all realizations32 of the sensitive variables. To achieve this, we propose to estimate the optimal IDR by optimizing33 a quantile- or infimum-based objective, respectively, for continuous or discrete sensitive variables.34 Our idea falls along the lines of work that considers algorithmic fairness [1] while extending it to35 the setting of causal inference [2] in the sense that decisions are driven by causality rather than a36 general utility function. We show in our empirical analyses that this leads to fairer and safer real-life37\nSubmitted to 36th Conference on Neural Information Processing Systems (NeurIPS 2022). Do not distribute.\ndecisions with little sacrifice of the overall performance. This optimization problem is then shown38 to be equivalent to a weighted classification problem where most existing statistical and machine39 learning classifiers can be readily applied.40\nAssuming that a large outcome value is preferable, optimal IDRs are traditionally derived through41 maximizing the mean outcome of the sample population. In this paper, we are interested in a specific42 yet broadly applicable setting of learning that involves sensitive variables. We consider offline43 learning where sensitive variables are collected and can be used in training the IDRs, but they cannot44 be used as input in the resulting IDRs. This is a setting commonly considered in the fairness and45 privacy-related literature for classification (e.g., [3]), but not from a causal standpoint. When there46 exist important variables that are simply left out from training, the estimated IDR will be biased.47 This bias can be removed if all important variables are used during training, which we will show in48 Section 3.1 a mean-optimal approach. The optimal action maximizes the mean outcome where the49 mean is taken over the sensitive variables, conditioning on other variables. This method, however,50 has no control of the disparity in sensitive variables. Subjects with different sensitive values may51 report large outcome differences, hence unfairly or unsafely treated. Therefore, objective functions52 with robustness guarantees for sensitive variables are preferred, since they offer protection to subjects53 in the lower tail of the outcome distribution with regards to the sensitive values.54\nFor illustration, we consider a toy example with binary actions, A \u2208 {\u22121, 1}. We note that the55 decision can only be made based on the variable X whereas S is a sensitive variable. The setup is56 shown in Table 1 and partial simulation results are shown in Table 2. The details can be found in57 Section 4.1 under Example 1. We consider vulnerable subjects as those with low outcome values,58 as highlighted in red in Table 1 (A full definition will be given in Section 3.2). For X \u2264 0.5, the59 traditional mean-optimal rule assigns action A = 1 as it achieves the largest average reward across60 S = 0 and S = 1. However, this action results in great harm for subjects with S = 1 as they could61 get the worst expected outcome of 0. On the contrary, the proposed RISE improves the worst-case62 outcome by assigning A = \u22121, protecting the vulnerable subjects. Likewise, for X > 0.5, the mean-63 optimal rule assigns A = \u22121 while the proposed rule assigns A = 1 protecting those with S = 0 that64 could have experienced an outcome of 5. Compared to the mean-optimal rule, the proposed RISE65 achieves a much larger reward among vulnerable subjects while maintaining a comparable overall66 expected reward. The worst-case outcomes of the rule by the proposed RISE are colored in blue.67\nTable 1: Toy example setup.\nX \u2264 0.5 X > 0.5\nE(Y |X,S,A) S = 0 S = 1 S = 0 S = 1 A = \u22121 11 13 5 27 A = 1 30 0 15 13\nTable 2: Toy example results.\nAverage reward\nOverall Vulnerable\nMean-optimal rule 14.4 7.1 RISE 13 14\nMain contributions. Methodology-wise, 1) we propose a novel framework, RISE, to handle68 sensitive variables in causality-driven decision making. Robustness is introduced to improve the69 worst-case outcome caused by sensitive variables, and as a result, it reduces the outcome variation70 across subjects. The latter is directly associated with fairness and safety in decision making. To71 the best of our knowledge, we are among the first to propose a robust-type fairness criterion under72 causal inference. 2) We introduce a classification-based optimization framework that can easily73 leverage most existing classification tools catered to different functional classes, including state-of-74 the-art random forest, boosting, or neural network models. Application-wise, 3) the consideration of75 sensitive variables in decision learning is important to applications in policy, education, healthcare,76 etc. Specifically, we illustrate the application of RISE using three real-world examples from fairness77 and safety perspectives where robust decision rules are needed, across which we have observed78 robust performance of the proposed approach. From a fairness perspective, we consider a job training79 program where age is considered as a sensitive variable. From a safety perspective, we consider two80 applications to healthcare where lab measurements are considered as sensitive variables.81\n2 Related Work82\nOur work focuses on individualized decision rules, which aim at assigning treatment decision based83 on subject characteristics. See [4, 5, 6, 7] and references therein for a comprehensive review. In84\nAppendix A.1, we provide additional literature review on general IDRs under causal settings. Beyond85 the field of causal inference, fairness and safety, and robustness are two areas of research that extend86 well beyond the learning of IDRs. In the following, we provide a review on both, with focus given to87 work related to causal inference and IDRs.88\nFairness and safety in IDRs. The consideration of fairness and safety in machine learning has seen89 an explosion of interest in the past few years. We refer to [1, 8, 9, 10, 11, 12, 13, 14] and references90 therein for a review of this topic in classification and regression problems. In these work, sensitive91 variables are also referred to as sensitive or protected attributes. We extend the definition of sensitive92 variables to include delayed information that is not available at deployment as it is also suitable for93 this framework.94\nAmong earlier work, preprocessing approaches [3, 15, 16, 17] and inprocess training approaches95 [18, 11, 19] consider disentangling the input X from a known or unknown sensitive variable S so96 that the transformed X does not contain any information that can be used to trace back to S. Due97 to the causal nature of IDRs, effect of IDRs cannot be estimated consistently when an informative98 S is left out and the resulting rule is sub-optimal. This follows from the classic argument that any99 unmeasured confounding (i.e., S), if not accounted for, would lead to bias. Similar issues persist in100 contextual bandits [20, 21]. Inside the causal framework, [22, 23] extend fairness from prediction to101 policy learning using causal graphical models by incorporating fairness constraints. [24] considers102 counterfactual fairness that seeks to achieve conditional independence of the decisions via data103 preprocessing. Despite earlier efforts in bringing fairness into the causal framework, most of these104 approaches only ensure mean zero disparity in S but do not have robustness guarantees in the sense105 that the variance of the disparity in S is not controlled. Besides, most examples consider a single106 categorical sensitive variable, but not multiple or continuous ones.107\nRobustness in IDRs. Recently the statistical literature has witnessed a growing interest in developing108 robust methods for estimating IDRs. They introduce robustness into the objective function by using109 quantile-optimal treatment regimes or mean-optimal treatment regimes under certain constraints110 to improve the gain of individuals at the lower tail of the reward spectrum [25, 26, 27, 28, 29].111 Robustness, in their sense, pertains to the outcome distribution subject to sampling error. When112 sensitive variables are present, we consider instead the robustness of the outcome distribution subject113 to the uncertainty due to sensitive variables, providing a more targeted way of ensuring robustness,114 which is directly related to fairness and safety. Compared to algorithms based on explicit fairness115 constraints (for example [30, 31] in classification and [22, 24] in causal inference) that seek to remove116 the disparity across different values of S, our method reduces the variance of disparity across S. In117 addition, constraint-based approaches typically require specialized optimization procedures whereas118 our approach presents an elegant and systematic way for optimization. To our knowledge, we are the119 first few to consider decision fairness via a robust objective under the causal framework.120\n3 Robust Decision Learning Framework with Sensitive Variables121\n3.1 Preliminaries122\nNotation. We let random variables be represented by upper-case letters, and their realizations be123 represented by lower-case letters. Suppose there are n independent subjects sampled from a given124 population. For subject i, let Ai \u2208 {\u22121, 1} denote a binary treatment assignment and Yi denote125 the corresponding outcome. Without loss of generality, we assume a larger value of outcome is126 desirable. Under the potential outcomes framework [32, 33], let Yi(\u22121) be the potential outcome127 had the subject been assigned to control and Yi(1) be the potential outcome had the subject been128 assigned to treatment. Let Xi \u2208 X be the feature vector and, for now, Si be a single sensitive variable.129 Extension to multiple sensitive variables is presented in Section 3.4. We consider S \u2208 S where130 S = {1, . . . ,K} if S is discrete and S = R if S is continuous.131 Definition of sensitive variables. We define sensitive variables that are important to the intervention132 decision, but their inclusion in decision making is prohibited. Formally, consider variables X and133 S that are both available during model training and are both determinants of conditional average134 treatment effect [34]. While X and S may be both involved in training, the derived decision rule d(\u00b7)135 precludes the input of S due to sensitive concerns. Hence, the derived IDR is only a function with136 the form d(X) : X \u2192 A. Following the above definition, we consider an offline learning framework137\nwhere sensitive variables are collected and can be used in obtaining the IDRs, but they cannot be used138 in the resulting IDRs.139 Assumption 1. Assume the following conditions hold:140\n(1a) Consistency: Y = Y (\u22121)1(A = \u22121) + Y (1)1(A = 1).141 (1b) Positivity: 0 < Pr(A = 1|X,S) < 1.142 (1c) Unconfoundedness: {Y (\u22121), Y (1)} \u22a5 A|{X,S} and {Y (\u22121), Y (1)} \u0338\u22a5 A|X .143\nAssumption 1a is the standard consistency assumption in causal inference and Assumption 1b states144 that every subject has a nonzero probability of getting the treatment. Assumption 1c states that145 given X and S, the potential outcomes are independent of the treatment assignments. Besides, the146 unconfoundedness does not hold when only X is conditional, signifying the importance of S. Under147 causal settings, Assumption 1c ensures that treatment effects cannot be non-parametrically identifiable148 without S (See [35, 34, 36, 37, 38] and references therein). Approaches such as disentanglement149 of X from S under supervised learning settings mentioned in Section 2 will introduce bias towards150 estimating the IDR.151\nNaive approaches that omit sensitive variables. When S is not available for future deployment, a152 naive approach is to maximize EX{E(Y |X,A = d(X))} over d using (X,A, Y ) during the training153 procedure. This approach will introduce bias in the estimation of potential outcomes and lead to a154 suboptimal IDR due to the unmeasured confounder S.155\nMean-optimal approaches that use the sensitive variables. It is thus important that one includes S156 into the training procedure. For example, if we consider the value function framework (i.e., expected157 outcome) used by most existing works such as [39, 40], we can show that158\nE{Y (d)} = EX,S [ E(Y (d)|X,S) ] = EX [ ES|X{E(Y (d)|X,S)} ] (1)\n= EX [ ES|X{E(Y |X,S,A = d(X))} ] \u0338= EX [ E(Y |X,A = d(X)) ] ,\nwhere the third equality in (1) holds by Assumption 1 and the last inequality also indicates the159 naive approaches without using S will in general fail. Then one valid approach is to maximize160 EX [ ES|X{E(Y |X,S,A = d(X))} ] over d using (X,S,A, Y ). The optimal IDR under this crite-161 rion is, for every X \u2208 X,162\nd\u0303(X) \u2208 sign(ES|X{E(Y |X,S,A = 1)} \u2212 ES|X{E(Y |X,S,A = \u22121)}),\nwhich guarantees to find the treatment that maximizes the conditional expected outcome given each163 X by averaging out the effect of the sensitive variable S. The mean-optimal approaches, however,164 fail to control the disparities across realizations of the sensitive variables due to the integration over165 S, which may lead to unsatisfactory decisions to certain subgroups, as illustrated in the toy example166 in Section 1.167\n3.2 Robust Optimality with Sensitive Variables168\nDriven by the limitation of existing approaches, our goal is to derive a robust decision rule that169 maximizes the worst-case scenarios of subjects when some sensitive information is not available at170 the time of deploying the decision rule. Specifically, our robust decision learning framework draws171 decisions based on individuals\u2019 available characteristics summarized in the vector X without the172 sensitive variable S, while improving the worst-case outcome of subjects in terms of the sensitive173 variable in the population. Formally, given a collection D of all treatment decision rules depending174 only on X , the proposed RISE approach estimates the following IDR, which is defined as175\nd\u2217 \u2208 argmaxd\u2208DEX [ GS|X{E(Y |X,S,A = d(X))} ] , (2)\nwhere GS|X(\u00b7) could be chosen as some risk measure for evaluating E(Y |X,S,A = d(X)) for each176 S \u2208 S. Examples include variance, conditional value at risk, quantiles, etc. In this paper, we consider177 GS|X as the conditional quantiles (for a continuous S) or the infimum (for a discrete S) over S.178\nSpecifically, for a discrete S, GS|X is consider as an infimum operator of E(Y |X,S,A = d(X)) over S. We thus aim to find\nd\u2217 \u2208 argmaxDEX [ infs\u2208S{E(Y |X,S = s,A = d(X))} ] ,\nwhere inf is the infimum taken with respect to E(Y |X, s,A = d(X)) over s \u2208 S. This implies that for a given X , d\u2217(X) assigns the treatment that yields the best worst-case scenario among all possible values of S for every X \u2208 X, or equivalently,\nd\u2217(X) \u2208 sign(infs\u2208S{E(Y |X,S = s,A = 1)\u2212 infs\u2208S{E(Y |X,S = s,A = \u22121)}).\nFor a continuous S, we consider GS|X{E(Y |X,S,A = d(X))} as Q\u03c4S|X{E(Y |X,S,A = d(X))}, which is the \u03c4 -th quantile of {E(Y |X,S,A = d(X))} and \u03c4 \u2208 (0, 1) is the quantile level of interest. Specifically, Q\u03c4S|X{E(Y |X,S,A = d(X))} = inf{t : F (t) \u2265 \u03c4} with F denoting the conditional distribution function of E(Y |X,S,A = d(X)) given X and d. Note the randomness behind E(Y |X,S,A = d(X)) given X and d is fully determined by the sensitive variable S. Then optimal IDR under this criterion is defined as\nd\u2217 \u2208 argmaxDEX [ Q\u03c4S|X{E(Y |X,S,A = d(X))} ] .\nThis implies that for a given X , d\u2217(X) assigns a treatment that yields the largest \u03c4 -th quantile of the outcome over the distribution related to S, or equivalently,\nd\u2217(X) \u2208 sign({Q\u03c4S|X{E(Y |X,S,A = 1)} \u2212Q \u03c4 S|X{E(Y |X,S,A = \u22121)}).\nWe let \u03c4 = 0.25 throughout the paper and suppress \u03c4 for simplicity. Results on varying the value of179 \u03c4 is provided in Appendix; see Section 4.1 for details.180\nIdentifying vulnerable subjects. Our RISE framework provides a natural way to define vulnerable181 groups. Specifically, for a discrete S, if infS{E(Y |X,S,A = 1)} > infS{E(Y |X,S,A = 0)}, then182 arg infS{E(Y |X,S,A = 0)} is vulnerable given X , otherwise is arg infS{E(Y |X,S,A = 1)}.183 In other words, the vulnerable subjects are those in the worst-off group that needs protection.184 Similarly, for a continuous S, if QS{E(Y |X,S,A = 1)} > QS{E(Y |X,S,A = 0)}, then the185 set {S : E(Y |X,S,A = 0) \u2264 QS{E(Y |X,S,A = 0)}} defines the vulnerable subjects given X ,186 otherwise this group is defined as {S : E(Y |X,S,A = 1) \u2264 QS{E(Y |X,S,A = 1)}}.187\n3.3 Estimation and Algorithm188\nHere we provide a transformation of the proposed RISE from an optimization problem to a weighted189 classification problem. There are several advantages to this conversion: 1) The optimization problem190 defined in (2) involves a nonsmooth and nonconvex objective function that could lead to computational191 challenges. 2) With multiple powerful statistical and machine learning toolbox to choose from, a192 classification problem can be more readily solved in practice. Hyperparameter tuning and model193 selection could be conducted to further boost performance. (3) Compared to a direct optimization194 of (2), a classification-based optimizer allows the use of off-the-shelf software packages that can be195 tailored to different functional classes or incorporate different properties such as model sparsity.196 Proposition 1. Maximizing the objective function in (2) is equivalent to maximizing\nEX { 1(d(X) = 1)[GS|X{E(Y |X,S,A = 1)} \u2212GS|X{E(Y |X,S,A = \u22121)}] } .\nWith Proposition 1 and a proper estimator of the outcome model E(Y |X,S,A) using our training197 data Dn = {Xi, Si, Ai, Yi}ni=1, we replace the expectation of Yi by its estimate Y\u0302i and solve the198 following problem.199\nargmaxd\u2208Dn \u22121 \u2211n i=1[1(d(xi) = 1){g1(xi)\u2212 g2(xi)}], (3)\nwhere g1(xi) = Gs|x{Y\u0302i(xi, s, ai = 1)} and g2(xi) = Gs|x{Y\u0302i(xi, s, ai = \u22121)}. Note that200 g1(xi) \u2212 g2(xi) may not be positive, which makes Problem (3) difficult to solve. We have the201 following key proposition 2 to address this issue and transform it into a classification problem.202 Proposition 2. Maximizing the empirical objective in (3) is equivalent to a weighted classification203 problem of minimizing204\nn\u22121 \u2211n\ni=1 1[sgn{g1(xi)\u2212 g2(xi)} \u00b7 f(xi) < 0] \u00b7 |g1(xi)\u2212 g2(xi)|, (4)\nwith features xi, the true label sgn{g1(xi)\u2212 g2(xi)}, and the sample weight |g1(xi)\u2212 g2(xi)|, for205 subject i, i = 1, . . . , n.206\nWith Proposition 2, we have transformed the optimization problem (2) into a weighted classification207 problem (4) where for subject i with features xi, the true label is sgn{g1(xi) \u2212 g2(xi)} and the208 sample weight is |g1(xi) \u2212 g2(xi)|. The estimated optimal decision rule by (4) is then given by209 d\u0302(x) = sgn{f\u0302(x)}. The proof of Proposition 1 and Proposition 2 is presented in Appendix A.2.210 Algorithm 1 provides an algorithmic overview. The inner expectation E(Y |X,S,A) can be modeled211 as Y\u0302 (X,S,A) using a twin model separated by the treatment and control groups. For a continuous S,212 we propose to estimate G(X,A) = QS|X,A{E(Y |X,S,A)} via a quantile regression of Y\u0302 on X but213 without S. For a discrete S, we propose to obtain an estimate of G(X,A) = infS{E(Y |X,S,A)} by214 finding the minimum among {E(Y |X,S = 1, A), . . . , E(Y |X,S = K,A)}. The estimated decision215 rule can then be obtained from the weighted classification. In our implementation, neural networks216 are used to fit models in the training data sets. The details on modeling and hyperparameter tuning217 via cross-validations are given in Appendix A.3. A Python package rise based on neural networks218 is built. Note that the model choices are flexible.219\nAlgorithm 1 RISE (Robust individualized decision learning with sensitive variables) Input Training data Dn = {Yi, Ai, Xi, Si}ni=1 Output Estimated decision rule d\u0302\n1: Y\u0302i(xi, si, ai)\u2190Model E(Y |X,S,A = a) using Dn with a = 1 and a = \u22121, respectively. 2: if S is continuous then 3: g1(xi)\u2190Model QS|X,A{E(Y |X,S,A = a)} via quantile regressions of Y\u0302i(xi, si, ai) on xi, for Dn\nwith a = 1. 4: g2(xi)\u2190Model QS|X,A{E(Y |X,S,A = a)} via quantile regressions of Y\u0302i(xi, si, ai) on xi, for Dn\nwith a = \u22121. 5: if S is discrete then 6: g1(xi)\u2190 Compute infs\u2208S{Y\u0302i(xi, s, ai = 1)} for every i. 7: g2(xi)\u2190 Compute infs\u2208S{Y\u0302i(xi, s, ai = \u22121)} for every i. 8: d\u0302\u2190 Build a weighted classification model with features xi, label sgn{g1(xi)\u2212g2(xi)}, and sample weight |g1(xi)\u2212 g2(xi)|. 9: Return d\u0302\n3.4 Extension to multiple discrete sensitive variables220\nFor multiple discrete sensitive variables, similar estimation procedure can be conducted as outlined221 in Section 3.3. Suppose there are L discrete sensitive variables, i.e., S = {S1, S2, . . . , SL}. The222 inner expectation E(Y |X,S1, . . . , SL, A) can be obtained with a twin model of Y on X and all S223 for each treatment level. The infimum over S is obtained by finding the minimum iterating space224 of possible parameter values for each sensitive variable. See Section 4.2 for an example of using225 multiple discrete sensitive variables. We will discuss in Section 5 the challenges and future work226 related to scenarios with multiple continuous sensitive variables or that with a mixture of continuous227 and discrete sensitive variables.228\n4 Numerical Studies229\nIn this section, we perform extensive numerical experiments to investigate the merit of robustness of230 the proposed framework via simulations and three real-data applications. The results demonstrate231 that the proposed rules achieve a robust objective with sensitive variables unavailable at the time of232 decision while maintaining comparable mean outcomes.233\nCompared approaches. For comparison, we consider the naive and mean-optimal approaches234 described in Section 3.1, which correspond to different choices of G(\u00b7) functions. The naive decision235 rule that simply disregard information of S, denoted as Base, can be formulated in our optimization236 framework of (2) by letting G(X,A) = E(Y |X,A). The IDR can be estimated directly by fitting237 a model of Y on X in each treatment arm. The resulting IDR is not sensitive variables-aware and238 is biased due to confounding, as discussed. Another IDR that resembles traditional mean-optimal239 decision rules, denoted as Exp, can be formulated as G(X,S,A) = E(Y |X,S,A). This can be240 obtained by training a classification model without S, i.e., only using X , after obtaining an outcome241 model for the inner expectation E(Y |X,S,A). Note that this approach is not robust to extreme242\nbehaviors in S. The modeling approaches described in Appendix A.3 applies to here. We also remark243 that there is limited work in the IDR-related literature that can be immediately compared with ours.244\nEvaluation metrics. 1) Objective: the quantile objective is estimated and reported for a continuous245 S and the infimum objective is for a discrete S. The objective, when \u03c4 < 0.5, (here \u03c4 = 0.25)246 represents the value of the \u201clow performers\u201d among all possible value of S under a given d. 2)247 Value: the value function, or expected reward used by the most existing methods, such as [39, 40],248 is defined as V (d) = E{Y (d)}. It represents the \u201caverage performers\u201d. For randomized trials, an249 unbiased estimator of V (d) is given by V\u0302 (d) = { \u2211T i=1 Yi1(Ai = d\u0302)/\u03c0(Ai,Xi)}/{ \u2211T i=1 1(Ai =250 d\u0302)/\u03c0(Ai,Xi)} [41], where T is the sample size of the test data. For observational studies, the value251 is estimated with V\u0302 (d) = T\u22121 \u2211T i=1 Y\u0302i(xi, si, ai = d\u0302). We report the metrics among all subjects252 and among the potential vulnerable subgroup, respectively. For simulation, we consider training253 data and the testing data, respectively, with sample sizes of 5,000. For real-data applications, we254 consider a 80-20 split of the dataset into a training data and a testing data. Continuous covariates255 are standardized before the estimation. All results are based on 100 replications. Experiments are256 performed on a 6-core Intel Xeon CPU E5-2620 v3 2.40GHz equipped with 64GB RAM. Python257 code is provided as part of Supplementary Materials.258\n4.1 Simulation Studies259\nExample 1. Here we provide the detail for the simulation of the motivating example introduced in260 Section 1. The outcome is generated using the following model: Yi = 1(Xi > 0.5){5 + 101(Ai =261 1) + 22Si \u2212 241(Ai = 1)Si} + 1(Xi \u2264 0.5){11 + 191(Ai = 1) + 2Si \u2212 321(Ai = 1)Si} + \u03f5i,262 where the covariate Xi \u223c Unif [0, 1], treatment assignment Ai \u223c Bernoulli(0.5), and the noise263 \u03f5i \u223c N(0, 1). For a discrete type S, the sensitive variable Si \u223c Bernoulli(0.5). For a continuous264 type S, Si is generated from a mixture of beta distributions, Beta(4, 1) and Beta(1, 4), with equal265 mixing proportions.266\nExample 2. We generate the outcome Y using the following model: Yi = {0.5 + 1(Ai =267 1)+exp(Si)\u22122.5Si1(Ai = 1)}{1+Xi1\u2212Xi2+X2i3+exp(Xi4)}+{1+21(Ai = 1)+0.2 exp(Si)\u2212268 3.5Si1(Ai = 1)}{1+5Xi1\u22122Xi2+3Xi3+2 exp(Xi4)}+ \u03f5, where Xij \u223c U(0, 1), j = 1, . . . , 6,269 A satisfies log{P (Ai = 1|Xi)/P (A = 0|Xi)} = \u22120.6(Si+Xi1\u2212Xi2+Xi3\u2212Xi4+Xi5\u2212Xi6),270 and \u03f5i \u223c N(0, 1). For a continuous type S, Si is generated from a mixture of beta distributions,271 Beta(4, 1) and Beta(1, 4), with equal mixing proportions; for a discrete type S, we consider a binary272 Si that satisfies log{P (Si = 1|Xi)/P (Si = 0|Xi)} = \u22122.5+0.8(Xi1 +Xi2 +Xi3 +Xi4 +Xi5 +273 Xi6).274\nTable 3 summarizes the performance of the proposed IDRs compared to the mean criterion for275 Example 1 and Example 2. The proposed RISE achieves the largest objectives and improves the276 value among vulnerable subjects, while maintaining comparative overall values. As demonstrated in277 the toy example introduced in Section 1, we expect that RISE helps improve the value among the278 vulnerable subjects while maintaining a comparable overall value. As for the objective, intuitively,279 the proposed rule is expected to have a larger objective. We also point out that there is no direct280 relationship between the objective among all subjects versus the objective among vulnerable subjects.281 For example, using the toy example with setup in Table 1, and limiting to subjects with X \u2264 0.5 only,282 S = 1 is vulnerable and is assigned A = \u22121 by the proposed RISE. The objective among S = 1 is283 13 but the objective among both S = 0 and S = 1 is 12 = (11 + 13)/2, which is smaller than that284 among the vulnerable group. In other words, by protecting the vulnerable subjects, the proposed rule285 may lead to an increase in the outcome of the vulnerable group, and the gain may result in a higher286 outcome than the overall mean outcome.287\nIn the appendix, we consider for a continuous S different quantile criteria \u03c4 = 0.1 and 0.5, respec-288 tively, to test the robustness of the proposed RISE. Results show that when \u03c4 is small, there is more289 strength in the proposed method, as the algorithm aims to improve the worst-outcome scenarios.290 The proposed RISE has the largest gain in objective and value among vulnerable subjects when \u03c4291 is 0.1, and has similar performance as the compared approaches when \u03c4 is 0.5. Also, we consider292 a scenario where S is not involved in the data generation of Y , i.e., Assumption 1c is simplified as293 {Y (\u22121), Y (1)} \u22a5 A|X . The estimated objective and value function are similar across all compared294 approaches, which indicates the robustness of RISE. The details can be found in Appendix A.4.295\nWe present three real-data examples to showcase the robust performance of RISE. These applications297 consider either fairness or safety in the context of policy [42] and healthcare [43, 44] where sensitive298 variables exist. The information of data access is provided in Appendix A.5.299\nFairness in a job training program. To illustrate the implication of the proposed method from a300 fairness perspective, we consider the National Supported Work (NSW) program [42] for improving301 personalized recommendations of a job training program on increasing incomes. This program302 intended to provide a 6 to 18-month training for individuals in face of economic and social problems303 such as former drug addicts and juvenile delinquents. The original experimental dataset consists304 of 185 individuals who received the job training program (A = 1) and 260 individuals who did not305 (A = \u22121). The baseline covariates are age, years of schooling, race (1 = African Americans or306 Hispanics, 0 = others), married (1 = yes, 0 = no), high school diploma (1 = yes, 0 = no), earning in307 1974, and earning in 1975. The outcome variable is the earning in 1978. In the exploratory analysis308 using causal forest [45], we observe that age may play an important role in the causal effect of the309 job training program on the long-term post-market earning. In the following data example we use age310 as the sensitive variable S and other baseline covariates as X . The earnings in years 1974, 1975, and311 1978 are transformed by taking the logarithm of the earning plus one.312\nImprovement of HIV treatment. To illustrate the implication of the proposed method from a313 safety perspective when there is delayed information, we consider the ACTG175 dataset among HIV314 positive patients [43]. The original study considers a total of 2,139 patients who were randomly315 assigned into four treatment groups. In this data application, we focus on finding the optimal IDRs316 between two treatments: zidovudine combined with didanosine (A = \u22121) and zidovudine combined317 with zalcitabine (A = 1). The total number of patients receiving these two treatments is 1,046. The318 baseline covariates we consider are age, weight, CD4 T-cell amount at baseline, hemophilia (1 = yes,319 0 = no), homosexual activity (1 = yes, 0 = no), Karnofsky score, history of intravenous drug use (1 =320 yes, 0 = no), gender (1 = male, 0 = female), CD8 T-cell amount at baseline, race (1 = non-Caucasian,321 0 = Caucasian), number of days of previously received antiretroviral therapy, use of zidovudine in the322 30 days prior to treatment initiation (1 = yes, 0 = no), and symptomatic indicator (1 = symptomatic, 0323 = asymptomatic). The outcome variable is the CD4 T-cell amount at 96\u00b1 5 weeks from the baseline.324 We consider CD8 T-cell amount at baseline as the sensitive variable. The response of CD8 T-cell325 among HIV positive patients has not been fully understood [46]. Clinically, it is plausible that only326 CD4 is measured in clinical visits where treatments are based on, hence CD8 might not be measured327 and not used in decision making. As our exploratory analysis using causal forest shows, CD8 T-cell328 amount may play an important part in the treatment effect of the outcome.329\nSafe resuscitation for patients with sepsis. For this application, we apply the proposed method to330 treating sepsis, a life-threatening disease. This application intends to provide an example to apply331 our method with multiple categorical sensitive variables in the scenario where there is missing yet332 important information at the time of decision making. We apply the proposed method to a sepsis study333 from the University of Pittsburgh Medical Center (UPMC). The original study cohort includes 30,687334\npatients with Sepsis-3 [44] within 6 hours of hospital arrival from 14 UPMC hospitals between 2013335 and 2017. For our data analysis, we consider X to be baseline patient characteristics 4 hours before336 sepsis onset, which includes patient demographics of age, gender (1 = male, 0 = female), race (1 =337 Caucasian, 0 = others), and weight, and vital signs of usage of mechanical ventilation (1 = yes, 0 =338 no), respiratory rate, temperature, intravenous fluids (1 = yes, 0 = no), Glasgow Coma Scale score,339 platelets, blood urea nitrogen, white blood cell counts, glucose, creatinine. We consider two sensitive340 variables, lactate and Sequential Organ Failure Assessment (SOFA) score 4 hours before sepsis onset.341 Note that their measurements are obtained retrospectively after treatment decisions have been made342 and are not available at times of decision. According to the new definition of Sepsis-3 [47], a serum343 lactate level >2 mmol/L is considered to be in critical conditions and is highly likely to indicate a344 septic shock. Also, a SOFA score greater than 6 has been associated with a higher mortality [48, 49].345 The treatment option is whether the patient took any vasopressors during the first 24 hours after sepsis346 onset. The outcome is patient survival at day 90. The analysis cohort contains 6,539 patients in total.347 We are interested in making decision about whether to treat patients with vasopressors in the first 24348 hours after sepsis onset given the measurements of lactate and SOFA are not available at the time of349 decision making. Additional rational and background on this example is provided in Appendix A.5.350\nResults. Table 4 presents the performance of various IDRs on the three applications. As expected,351 RISE has the largest objective as well as value among vulnerable subjects. The patterns are similar to352 that in the synthetic experiments in Section 4.1. In applications to the job training data and the sepsis353 study, results show that RISE has a larger value among all subjects than other IDRs. This is possible354 when there are more gains in the vulnerable subjects than other subjects, which further demonstrate355 the superiority of the proposed approach in improving worst-case outcomes caused by sensitive356 variables. We provide visualizations by Shapley additive explanations (SHAP) [50] for RISE and357 Exp, respectively, in Appendix A.5 about feature importance in the final classification models to358 help interpret important covariates in making the decisions. The SHAP approach provides united359 values to describe the correlation between each feature and the predicted decision rule, respectively360 [50]. Overall, the direction of correlations is similar for RISE and Exp, but their ranking of feature361 importance may be different.362\n5 Discussion363\nWe have proposed RISE, a robust decision learning framework with a novel quantile-, or infimum-364 optimal treatment objective intended to improve the worst-case scenarios of individuals when deci-365 sions with uncertainty are needed to be made with sensitive yet important information missing. Our366 approach can be applied to a board of applications, including but not limited to politics, education,367 healthcare, etc. For multiple continuous sensitive variables, the estimated decision rule by RISE can368 be easily obtained by fitting similar quantile regression as described in Section 3.3. For a mixture of369 continuous and discrete sensitive variables, the estimated rule can be obtained by taking infimum370 over the discrete ones, then obtaining quantile over the continuous ones. However, challenges remain371 in find vulnerable subjects described in Section 3.2 under these settings as it may be computationally372 difficult to find a vulnerable set of S when they are multi-dimensional. Another future work includes373 extension of the current binary treatment option to a multi-treatment option.374\nReferences375 [1] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. Fairness376 through awareness. In Proceedings of the 3rd Innovations in Theoretical Computer Science377 Conference, pages 214\u2013226, 2012.378\n[2] Donald B Rubin. Causal inference using potential outcomes: Design, modeling, decisions.379 Journal of the American Statistical Association, 100(469):322\u2013331, 2005.380\n[3] Faisal Kamiran and Toon Calders. Data preprocessing techniques for classification without381 discrimination. Knowledge and Information Systems, 33(1):1\u201333, 2012.382\n[4] Bibhas Chakraborty, Susan Murphy, and Victor Strecher. Inference for non-regular parameters383 in optimal dynamic treatment regimes. Statistical Methods in Medical Research, 19(3):317\u2013343,384 2010.385\n[5] Bibhas Chakraborty and Erica E Moodie. Statistical Methods for Dynamic Treatment Regimes.386 Springer, 2013.387\n[6] Eric B Laber, Daniel J Lizotte, Min Qian, William E Pelham, and Susan A Murphy. Dynamic388 treatment regimes: Technical challenges and applications. Electronic Journal of Statistics,389 8(1):1225\u20131272, 2014.390\n[7] Michael R Kosorok and Erica EM Moodie. Adaptive treatment strategies in practice: planning391 trials and analyzing data for personalized medicine. SIAM, 2015.392\n[8] Kush R Varshney. Engineering safety in machine learning. In 2016 Information Theory and393 Applications Workshop (ITA), pages 1\u20135. IEEE, 2016.394\n[9] Solon Barocas, Moritz Hardt, and Arvind Narayanan. Fairness in machine learning. Nips395 tutorial, 1:2, 2017.396\n[10] Razieh Nabi and Ilya Shpitser. Fair inference on outcomes. In Proceedings of the AAAI397 Conference on Artificial Intelligence, volume 32, 2018.398\n[11] Tatsunori Hashimoto, Megha Srivastava, Hongseok Namkoong, and Percy Liang. Fairness399 without demographics in repeated loss minimization. In International Conference on Machine400 Learning, pages 1929\u20131938. PMLR, 2018.401\n[12] Alexandra Chouldechova and Aaron Roth. A snapshot of the frontiers of fairness in machine402 learning. Communications of the ACM, 63(5):82\u201389, 2020.403\n[13] Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. A404 survey on bias and fairness in machine learning. ACM Computing Surveys (CSUR), 54(6):1\u201335,405 2021.406\n[14] Dana Pessach and Erez Shmueli. A review on fairness in machine learning. ACM Computing407 Surveys (CSUR), 55(3):1\u201344, 2022.408\n[15] Michael Feldman, Sorelle A Friedler, John Moeller, Carlos Scheidegger, and Suresh Venkata-409 subramanian. Certifying and removing disparate impact. In Proceedings of the 21th ACM410 SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 259\u2013268,411 2015.412\n[16] Elliot Creager, David Madras, J\u00f6rn-Henrik Jacobsen, Marissa Weis, Kevin Swersky, Toniann413 Pitassi, and Richard Zemel. Flexibly fair representation learning by disentanglement. In414 International Conference on Machine Learning, pages 1436\u20131445. PMLR, 2019.415\n[17] Prasanna Sattigeri, Samuel C Hoffman, Vijil Chenthamarakshan, and Kush R Varshney. Fairness416 gan: Generating datasets with fairness properties using a generative adversarial network. IBM417 Journal of Research and Development, 63(4/5):3\u20131, 2019.418\n[18] Alex Beutel, Jilin Chen, Zhe Zhao, and Ed H Chi. Data decisions and theoretical implications419 when adversarially learning fair representations. arXiv preprint arXiv:1707.00075, 2017.420\n[19] Preethi Lahoti, Alex Beutel, Jilin Chen, Kang Lee, Flavien Prost, Nithum Thain, Xuezhi421 Wang, and Ed Chi. Fairness without demographics through adversarially reweighted learning.422 Advances in Neural Information Processing Systems, 33:728\u2013740, 2020.423\n[20] Matthew Joseph, Michael Kearns, Jamie H Morgenstern, and Aaron Roth. Fairness in learning:424 Classic and contextual bandits. Advances in Neural Information Processing Systems, 29, 2016.425\n[21] Vishakha Patil, Ganesh Ghalme, Vineet Nair, and Yadati Narahari. Achieving fairness in the426 stochastic multi-armed bandit problem. In Proceedings of the AAAI Conference on Artificial427 Intelligence, pages 5379\u20135386, 2020.428\n[22] Junzhe Zhang and Elias Bareinboim. Fairness in decision-making\u2014the causal explanation429 formula. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 32, 2018.430\n[23] Razieh Nabi, Daniel Malinsky, and Ilya Shpitser. Learning optimal fair policies. In International431 Conference on Machine Learning, pages 4674\u20134682. PMLR, 2019.432\n[24] Haoyu Chen, Wenbin Lu, Rui Song, and Pulak Ghosh. On learning and testing of counterfactual433 fairness through data preprocessing. arXiv preprint arXiv:2202.12440, 2022.434\n[25] Lan Wang, Yu Zhou, Rui Song, and Ben Sherwood. Quantile-optimal treatment regimes.435 Journal of the American Statistical Association, 113(523):1243\u20131254, 2018.436\n[26] Yuanjia Wang, Haoda Fu, and Donglin Zeng. Learning optimal personalized treatment rules in437 consideration of benefit and risk: with an application to treating type 2 diabetes patients with438 insulin therapies. Journal of the American Statistical Association, 113(521):1\u201313, 2018.439\n[27] Zhengling Qi, Jong-Shi Pang, and Yufeng Liu. On robustness of individualized decision rules.440 Journal of the American Statistical Association, pages 1\u201315, 2022.441\n[28] Zhengling Qi, Ying Cui, Yufeng Liu, and Jong-Shi Pang. Estimation of individualized decision442 rules based on an optimized covariate-dependent equivalent of random outcomes. SIAM Journal443 on Optimization, 29(3):2337\u20132362, 2019.444\n[29] Ethan X. Fang, Zhaoran Wang, and Lan Wang. Fairness-oriented learning for optimal individu-445 alized treatment rules. Journal of the American Statistical Association, 0(0):1\u201314, 2022.446\n[30] Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rogriguez, and Krishna P Gummadi.447 Fairness constraints: Mechanisms for fair classification. In Artificial Intelligence and Statistics,448 pages 962\u2013970. PMLR, 2017.449\n[31] Brian Hu Zhang, Blake Lemoine, and Margaret Mitchell. Mitigating unwanted biases with450 adversarial learning. In Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and451 Society, pages 335\u2013340, 2018.452\n[32] Donald B Rubin. Bayesian inference for causal effects: The role of randomization. The Annals453 of Statistics, pages 34\u201358, 1978.454\n[33] Jerzy Splawa-Neyman, Dorota M Dabrowska, and TP Speed. On the application of probability455 theory to agricultural experiments. essay on principles. section 9. Statistical Science, pages456 465\u2013472, 1990.457\n[34] Donald B Rubin. Estimating causal effects of treatments in randomized and nonrandomized458 studies. Journal of Educational Psychology, 66(5):688, 1974.459\n[35] Jerzy Neyman. Sur les applications de la thar des probabilities aux experiences agaricales:460 Essay des principle. Excerpts reprinted (1990) in English. Statistical Science, 5:463\u2013472, 1923.461\n[36] Paul W Holland. Statistics and causal inference. Journal of the American statistical Association,462 81(396):945\u2013960, 1986.463\n[37] Guido W. Imbens and Joshua D. Angrist. Identification and estimation of local average treatment464 effects. Econometrica, 62(2):467\u2013475, 1994.465\n[38] Judea Pearl. Causality. Cambridge University Press, 2009.466\n[39] Charles F Manski. Statistical treatment rules for heterogeneous populations. Econometrica,467 72(4):1221\u20131246, 2004.468\n[40] Min Qian and Susan A Murphy. Performance guarantees for individualized treatment rules.469 Annals of Statistics, 39(2):1180, 2011.470\n[41] Susan A Murphy, Mark J van der Laan, James M Robins, and Conduct Problems Prevention Re-471 search Group. Marginal mean models for dynamic regimes. Journal of the American Statistical472 Association, 96(456):1410\u20131423, 2001.473\n[42] Robert J LaLonde. Evaluating the econometric evaluations of training programs with experi-474 mental data. The American Economic Review, pages 604\u2013620, 1986.475\n[43] Scott M Hammer, David A Katzenstein, Michael D Hughes, Holly Gundacker, Robert T476 Schooley, Richard H Haubrich, W Keith Henry, Michael M Lederman, John P Phair, Manette477 Niu, et al. A trial comparing nucleoside monotherapy with combination therapy in hiv-infected478 adults with cd4 cell counts from 200 to 500 per cubic millimeter. New England Journal of479 Medicine, 335(15):1081\u20131090, 1996.480\n[44] Christopher W Seymour, Vincent X Liu, Theodore J Iwashyna, Frank M Brunkhorst, Thomas D481 Rea, Andr\u00e9 Scherag, Gordon Rubenfeld, Jeremy M Kahn, Manu Shankar-Hari, Mervyn Singer,482 et al. Assessment of clinical criteria for sepsis: for the third international consensus definitions483 for sepsis and septic shock (sepsis-3). The Journal of the American Medical Association,484 315(8):762\u2013774, 2016.485\n[45] Stefan Wager and Susan Athey. Estimation and inference of heterogeneous treatment effects486 using random forests. Journal of the American Statistical Association, 113(523):1228\u20131242,487 2018.488\n[46] Sushma Boppana and Paul Goepfert. Understanding the CD8 T-cell response in natural HIV489 control. F1000Research, 7, 2018.490\n[47] Manu Shankar-Hari, Gary S Phillips, Mitchell L Levy, Christopher W Seymour, Vincent X491 Liu, Clifford S Deutschman, Derek C Angus, Gordon D Rubenfeld, Mervyn Singer, et al.492 Developing a new definition and assessing new clinical criteria for septic shock: for the third493 international consensus definitions for sepsis and septic shock (sepsis-3). The Journal of the494 American Medical Association, 315(8):775\u2013787, 2016.495\n[48] J-L Vincent, Rui Moreno, Jukka Takala, Sheila Willatts, Arnaldo De Mendon\u00e7a, Hajo Bruining,496 CK Reinhart, PeterM Suter, and Lambertius G Thijs. The SOFA (sepsis-related organ failure497 assessment) score to describe organ dysfunction/failure. On behalf of the working group on498 sepsis-related problems of the european society of intensive care medicine. Intensive Care499 Medicine, 22(7):707\u2013710, 1996.500\n[49] Flavio Lopes Ferreira, Daliana Peres Bota, Annette Bross, Christian M\u00e9lot, and Jean-Louis501 Vincent. Serial evaluation of the sofa score to predict outcome in critically ill patients. The502 Journal of the American Medical Association, 286(14):1754\u20131758, 2001.503\n[50] Scott M Lundberg and Su-In Lee. A unified approach to interpreting model predictions.504 Advances in Neural Information Processing Systems, 30, 2017.505\n[51] Christopher JCH Watkins and Peter Dayan. Q-learning. Machine Learning, 8(3):279\u2013292,506 1992.507\n[52] Susan A Murphy. Optimal dynamic treatment regimes. Journal of the Royal Statistical Society:508 Series B (Statistical Methodology), 65(2):331\u2013355, 2003.509\n[53] Erica EM Moodie, Thomas S Richardson, and David A Stephens. Demystifying optimal510 dynamic treatment regimes. Biometrics, 63(2):447\u2013455, 2007.511\n[54] Yair Goldberg and Michael R Kosorok. Q-learning with censored data. Annals of Statistics,512 40(1):529, 2012.513\n[55] Rui Song, Weiwei Wang, Donglin Zeng, and Michael R Kosorok. Penalized q-learning for514 dynamic treatment regimens. Statistica Sinica, 25(3):901, 2015.515\n[56] James M Robins, Miguel Angel Hernan, and Babette Brumback. Marginal structural models516 and causal inference in epidemiology. Epidemiology, 11(5):550\u2013560, 2000.517\n[57] Susan A Murphy. An experimental design for the development of adaptive treatment strategies.518 Statistics in Medicine, 24(10):1455\u20131481, 2005.519\n[58] James Robins, Liliana Orellana, and Andrea Rotnitzky. Estimation and extrapolation of optimal520 treatment and testing strategies. Statistics in Medicine, 27(23):4678\u20134721, 2008.521\n[59] Liliana Orellana, Andrea Rotnitzky, and James M Robins. Dynamic regime marginal structural522 mean models for estimation of optimal dynamic treatment regimes, part i: main content. The523 International Journal of Biostatistics, 6(2), 2010.524\n[60] Liliana Orellana, Andrea Rotnitzky, and James M Robins. Dynamic regime marginal structural525 mean models for estimation of optimal dynamic treatment regimes, part ii: proofs of results.526 The International Journal of Biostatistics, 6(2), 2010.527\n[61] Baqun Zhang, Anastasios A Tsiatis, Eric B Laber, and Marie Davidian. A robust method for528 estimating optimal treatment regimes. Biometrics, 68(4):1010\u20131018, 2012.529\n[62] Yingqi Zhao, Donglin Zeng, A John Rush, and Michael R Kosorok. Estimating individual-530 ized treatment rules using outcome weighted learning. Journal of the American Statistical531 Association, 107(499):1106\u20131118, 2012.532\n[63] Ying-Qi Zhao, Donglin Zeng, Eric B Laber, Rui Song, Ming Yuan, and Michael Rene Kosorok.533 Doubly robust learning for estimating individualized treatment with censored data. Biometrika,534 102(1):151\u2013168, 2015.535\n[64] Alberto Bietti, Alekh Agarwal, and John Langford. A contextual bandit bake-off. Journal of536 Machine Learning Research, 22(133):1\u201349, 2021.537\n[65] James M Robins. Optimal structural nested models for optimal sequential decisions. In538 Proceedings of the Second Seattle Symposium in Biostatistics, pages 189\u2013326. Springer, 2004.539\n[66] Erica EM Moodie, Robert W Platt, and Michael S Kramer. Estimating response-maximized540 decision rules with applications to breastfeeding. Journal of the American Statistical Association,541 104(485):155\u2013165, 2009.542\n[67] Tianxi Cai, Lu Tian, Peggy H Wong, and LJ Wei. Analysis of randomized comparative clinical543 trial data for personalized treatment selections. Biostatistics, 12(2):270\u2013282, 2011.544\n[68] Robin Henderson, Phil Ansell, and Deyadeen Alshibani. Regret-regression for optimal dynamic545 treatment regimes. Biometrics, 66(4):1192\u20131201, 2010.546\n[69] Peter F Thall, Hsi-Guang Sung, and Elihu H Estey. Selecting therapeutic strategies based on547 efficacy and death in multicourse clinical trials. Journal of the American Statistical Association,548 97(457):29\u201339, 2002.549\n[70] Kosuke Imai and Marc Ratkovic. Estimating treatment effect heterogeneity in randomized550 program evaluation. The Annals of Applied Statistics, 7(1):443\u2013470, 2013.551\n[71] Xuelin Huang, Sangbum Choi, Lu Wang, and Peter F Thall. Optimization of multi-stage552 dynamic treatment regimes utilizing accumulated data. Statistics in Medicine, 34(26):3424\u2013553 3443, 2015.554\n[72] Yebin Tao and Lu Wang. Adaptive contrast weighted learning for multi-stage multi-treatment555 decision-making. Biometrics, 73(1):145\u2013155, 2017.556\n[73] Mart\u00edn Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu557 Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al. {TensorFlow}: A system for558 {Large-Scale} machine learning. In 12th USENIX Symposium on Operating Systems Design559 and Implementation (OSDI 16), pages 265\u2013283, 2016.560\n[74] Yasser Sakr, Ulrich Jaschinski, Xavier Wittebole, Tamas Szakmany, Jeffrey Lipman, Silvio A561 \u00d1amendys-Silva, Ignacio Martin-Loeches, Marc Leone, Mary-Nicoleta Lupu, Jean-Louis562 Vincent, and ICON Investigators. Sepsis in intensive care unit patients: worldwide data from563 the intensive care over nations audit. Open Forum Infectious Diseases, 5(12):ofy313, 2018.564\n[75] Michael D Howell, Michael Donnino, Peter Clardy, Daniel Talmor, and Nathan I Shapiro. Occult565 hypoperfusion and mortality in patients with suspected infection. Intensive Care Medicine,566 33(11):1892\u20131899, 2007.567\n[76] Uma Krishna, Suresh P Joshi, and Mukesh Modh. An evaluation of serial blood lactate568 measurement as an early predictor of shock and its outcome in patients of trauma or sepsis.569 Indian Journal of Critical Care Medicine: peer-reviewed, official publication of Indian Society570 of Critical Care Medicine, 13(2):66, 2009.571\n[77] Lars W. Andersen, Julie Mackenhauer, Jonathan C. Roberts, Katherine M. Berg, Michael N.572 Cocchi, and Michael W. Donnino. Etiology and therapeutic approach to elevated lactate levels.573 Mayo Clinic Proceedings, 88(10):1127\u20131140, 2013.574\nChecklist575\nThe checklist follows the references. Please read the checklist guidelines carefully for information on576 how to answer these questions. For each question, change the default [TODO] to [Yes] , [No] , or577 [N/A] . You are strongly encouraged to include a justification to your answer, either by referencing578 the appropriate section of your paper or providing a brief inline description. For example:579\n\u2022 Did you include the license to the code and datasets? [Yes] See Section 2.580 \u2022 Did you include the license to the code and datasets? [No] The code and the data are581 proprietary.582 \u2022 Did you include the license to the code and datasets? [N/A]583\nPlease do not modify the questions and only use the provided macros for your answers. Note that the584 Checklist section does not count towards the page limit. In your paper, please delete this instructions585 block and only keep the Checklist section heading above along with the questions/answers below.586\n1. For all authors...587 (a) Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s588 contributions and scope? [Yes]589 (b) Did you describe the limitations of your work? [Yes] See Section 3.4 and Section 5.590 (c) Did you discuss any potential negative societal impacts of your work? [N/A]591 (d) Have you read the ethics review guidelines and ensured that your paper conforms to592 them? [Yes]593 2. If you are including theoretical results...594\n(a) Did you state the full set of assumptions of all theoretical results? [Yes] See Section 3.1.595 (b) Did you include complete proofs of all theoretical results? [Yes] See Section A.2.596\n3. If you ran experiments...597 (a) Did you include the code, data, and instructions needed to reproduce the main experi-598 mental results (either in the supplemental material or as a URL)? [Yes] See Section 4.599 Code is provided as part of Supplementary Materials.600\n(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they601 were chosen)? [Yes] See Section 4 and Section A.3.602\n(c) Did you report error bars (e.g., with respect to the random seed after running experi-603 ments multiple times)? [Yes] See Section 4 and Section A.4.604\n(d) Did you include the total amount of compute and the type of resources used (e.g., type605 of GPUs, internal cluster, or cloud provider)? [Yes] See Section 4. Experiments are606 performed on a 6-core Intel Xeon CPU E5-2620 v3 2.40GHz equipped with 64GB607 RAM.608\n4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...609 (a) If your work uses existing assets, did you cite the creators? [Yes] See Section 4.2 and610 Appendix A.5.611 (b) Did you mention the license of the assets? [Yes] The first two datasets are publicly612 available data, and the third dataset is proprietary. We have cited the published papers613 that originated the three data applications.614\n(c) Did you include any new assets either in the supplemental material or as a URL? [Yes]615 Code is provided as part of Supplementary Materials.616\n(d) Did you discuss whether and how consent was obtained from people whose data you\u2019re617 using/curating? [Yes] See Appendix A.5.618\n(e) Did you discuss whether the data you are using/curating contains personally identifiable619 information or offensive content? [Yes] See Appendix A.5. The first two real-data620 applications are publicly available data, and the third application uses deidentified data621 that all personally identifiable information has been removed.622\n5. If you used crowdsourcing or conducted research with human subjects...623 (a) Did you include the full text of instructions given to participants and screenshots, if624 applicable? [N/A]625 (b) Did you describe any potential participant risks, with links to Institutional Review626 Board (IRB) approvals, if applicable? [N/A]627 (c) Did you include the estimated hourly wage paid to participants and the total amount628 spent on participant compensation? [N/A]629"
      }
    ],
    "year": 2022,
    "abstractText": "This paper introduces RISE, a robust individualized decision learning framework 1 with sensitive variables, where sensitive variables are collectible data and important 2 to the intervention decision, but their inclusion in decision making is prohibited 3 due to reasons such as delayed availability or fairness concerns. The convention is 4 to ignore these sensitive variables in learning decision rules, leading to significant 5 uncertainty and bias. To address this, we propose a decision learning framework 6 to incorporate sensitive variables during offline training but do not include them 7 in the input of the learned decision rule during deployment. Specifically, from 8 a causal perspective, the proposed framework intends to improve the worst-case 9 outcomes of individuals caused by sensitive variables that are unavailable at the 10 time of decision. Unlike most existing literature that uses mean-optimal objectives, 11 the proposed learning framework robustifies sensitive variables via finding a newly 12 defined quantileor infimum-optimal decision rule for improving the worst-off 13 group among all sensitive variable realizations. The reliable performance of the 14 proposed method is demonstrated through synthetic experiments and three real-data 15 applications. 16",
    "creator": "pdftk 2.02 - www.pdftk.com"
  },
  "output": [
    [
      "1. **First paragraph: I do not think this is convincing.** ",
      "2. **L31: you say \u201cThe main question of interest is whether the learned IDR could yield similar outcomes across all realizations of the sensitive variables.\u201d - why is this the main question? I do not follow the logic as to why focus is on this.**",
      "3. **Table 1: you\u2019ll need to put some work into re-jigging this table.**",
      "4. **Related work: You use a version of this comment a few times in this section: \u201cSee [your listed references] and references therein for a comprehensive review\u201d. That is not helpful.**",
      "5. **Equation 2: why is d\u2217 not equal to the right-hand side but lies in the set of optimal IDRs?**",
      "6. **You appear to have dropped d\u2208D at the bottom of page four, in the aromas.**",
      "7. **What is the function of n\u22121 in equation 3? Or rather, why the inclusion of a weighting?**",
      "8. **Algorithm 1 would be more elegant if you looped over n rather than saying \u201cfor every i\u201d.**",
      "9. **Line 250: it would appear that you\u2019re missing the formatting for the indicator function in your estimator for V(d).**",
      "10. **It would be helpful, at least for the synthetic experiments, to visualise the underlying causal structure and if possible, how it fits in the IDR - the causal diagram is a key-part of causal inference so it would be interesting to see how you graphically include it (if possible).**",
      "11. **Line 309: what on earth is a \u201ccausal forest\u201d your reference title, [45], says \u2018random forest\u2019 but you must be referring to something else, hence what is a causal forest? Is there a reference?**",
      "12. **Line 328: again causal forest - reference?**",
      "13. **Line 341: explain why \u201clactate and Sequential Organ Failure Assessment (SOFA) score 4 hours before sepsis onset\u201d are sensitive variables?**"
    ],
    [
      "1. \"It is not clear to me whether the competing approaches that the proposed method compared to are competitive, representative, and exhaustive.\"",
      "2. \"The method also operates under the unconfoundedness assumption, which might not be easy to satisfy in practice.\"",
      "3. \"It will be desirable to carry out further synthetic experiments to understand the robustness of the proposed approach when various assumptions of the proposed approach is violated.\""
    ],
    [
      "1. \"language around 'sensitive' attribute seems a little general. I understand why it's used in some sense, but really it's just any attribute we won't have access to at deployment time - as shown in section 4, this could be a whole range of things which are not really aligned with what we consider 'sensitive' information\"",
      "2. \"similarly, I would say that the 'vulnerable' language doesn't really align with what I would consider a vulnerable population. Rather, it's a post-hoc definition of who the standard mean-outcome model doesn't work for\"",
      "3. \"for this reason, I find the results in Table 4 a little bit hard to interpret. The paper post-hoc defines who is in our vulnerable group as exactly those users that the baseline didn't work for, and now shows that the proposed method improves on them. This would be more convincing if it was a coherent group that we saw improvement on, as we could just as easily construct such a group with the reverse property (that the baseline performs better on). Unless I'm misunderstanding this!\"",
      "4. \"unclear about how estimation works of the quantile objective when X and S are correlated - what if we don't observe many values of S for regions of X? Are we relying mostly on the extrapolation ability of our Y-hat model?\"",
      "5. \"it's a little odd that in Table 4 RISE is best on the whole data, makes me think the results may be fairly noisy\"",
      "6. \"re: novelty, there is some related work I mention in the 'Questions' section which may make the statement 'we are among the first to propose a robust-type fairness criterion under causal inference' a little less true - although depends on exactly what those terms mean here\""
    ],
    [
      "1. The related work on Robustness in individualized decision rules is insufficient, so it is hard to judge the innovation of this paper in terms of robustness learning, because similar treatment regimes as quantile-optimal have already widely used in various cases.",
      "2. This proposed robust learning objective is essentially a minor modification to change the expectation Es|x into another measure, Gs|x , which is rather intuitive with no technical innovations.",
      "3. The derivation of the transformation from the raw problem to a weighted classification problem is not of great significance for practical training. As the optimization object is rather simple, it is reasonable to believe that neural networks can directly handle the original one.",
      "4. The comparison in the experiments is inadequate with only vanilla baselines provided. For a fair comparison, more modern methods should be included with appropriate adjustment on their objective function to fit the proposed learning objective in this paper."
    ]
  ],
  "review_num": 4,
  "item_num": [
    13,
    3,
    6,
    4
  ]
}